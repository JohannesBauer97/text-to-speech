{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# BaseDatasetConfig: defines name, formatter and path of the dataset.\n",
    "from TTS.tts.configs.shared_configs import BaseDatasetConfig\n",
    "\n",
    "output_path = \"tts_train_dir\"\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T14:07:47.391625500Z",
     "start_time": "2023-05-19T14:07:47.379596500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "dataset_config = BaseDatasetConfig(\n",
    "    formatter=\"ljspeech\", meta_file_train=\"metadata_train.csv\", path=\"../data/\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T14:08:00.086678100Z",
     "start_time": "2023-05-19T14:08:00.070678100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# GlowTTSConfig: all model related values for training, validating and testing.\n",
    "from TTS.tts.configs.glow_tts_config import GlowTTSConfig\n",
    "from TTS.tts.utils.text.\n",
    "config = GlowTTSConfig(\n",
    "    batch_size=32,\n",
    "    eval_batch_size=16,\n",
    "    num_loader_workers=8,\n",
    "    num_eval_loader_workers=8,\n",
    "    run_eval=True,\n",
    "    test_delay_epochs=-1,\n",
    "    epochs=100,\n",
    "    text_cleaner=\"phoneme_cleaners\",\n",
    "    use_phonemes=True,\n",
    "    phoneme_language=\"de-de\",\n",
    "    phoneme_cache_path=os.path.join(output_path, \"phoneme_cache\"),\n",
    "    print_step=1,\n",
    "    print_eval=False,\n",
    "    mixed_precision=True,\n",
    "    output_path=output_path,\n",
    "    datasets=[dataset_config],\n",
    "    save_step=1000,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T14:08:02.769613800Z",
     "start_time": "2023-05-19T14:08:02.761614400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:True\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:45\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n"
     ]
    }
   ],
   "source": [
    "from TTS.utils.audio import AudioProcessor\n",
    "ap = AudioProcessor.init_from_config(config)\n",
    "# Modify sample rate if for a custom audio dataset:\n",
    "# ap.sample_rate = 22050"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T14:08:03.639016100Z",
     "start_time": "2023-05-19T14:08:03.611017300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "from TTS.tts.utils.text.tokenizer import TTSTokenizer\n",
    "tokenizer, config = TTSTokenizer.init_from_config(config)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T14:08:04.496040900Z",
     "start_time": "2023-05-19T14:08:04.489015800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Found 12283 files in J:\\Text to Speech\\data\n"
     ]
    }
   ],
   "source": [
    "from TTS.tts.datasets import load_tts_samples\n",
    "train_samples, eval_samples = load_tts_samples(\n",
    "    dataset_config,\n",
    "    eval_split=True,\n",
    "    eval_split_max_size=config.eval_split_max_size,\n",
    "    eval_split_size=config.eval_split_size,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T14:08:05.182042500Z",
     "start_time": "2023-05-19T14:08:04.910015900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "from TTS.tts.models.glow_tts import GlowTTS\n",
    "model = GlowTTS(config, ap, tokenizer, speaker_manager=None)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T14:08:07.130513100Z",
     "start_time": "2023-05-19T14:08:06.919513900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " > Training Environment:\n",
      " | > Num. of CPUs: 8\n",
      " | > Num. of Torch Threads: 8\n",
      " | > Torch seed: 54321\n",
      " | > Torch CUDNN: True\n",
      " | > Torch CUDNN deterministic: False\n",
      " | > Torch CUDNN benchmark: False\n",
      " > Start Tensorboard: tensorboard --logdir=tts_train_dir\\run-May-19-2023_04+08PM-c81bf18\n",
      "\n",
      " > Model has 28610257 parameters\n"
     ]
    }
   ],
   "source": [
    "from trainer import Trainer, TrainerArgs\n",
    "trainer = Trainer(\n",
    "    TrainerArgs(), config, output_path, model=model, train_samples=train_samples, eval_samples=eval_samples\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T14:08:09.327585500Z",
     "start_time": "2023-05-19T14:08:08.951587200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001B[4m\u001B[1m > EPOCH: 0/100\u001B[0m\n",
      " --> tts_train_dir\\run-May-19-2023_04+08PM-c81bf18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Pre-computing phonemes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/12161 [00:00<58:23,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "das zɔl nuːn nɔɔʏ̯ə ʔaoːfɡaːbən bəkɔmən.\n",
      " [!] Character '̯' not found in the vocabulary. Discarding it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/12161 [00:01<42:45,  4.74it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zaɪ̯nə kaʁʁiːʁeː vaːɐ t͡suː ʔɛndeː, nɔx bəfoːɐ ziː bəɡɔnən hatə.\n",
      " [!] Character '͡' not found in the vocabulary. Discarding it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 468/12161 [01:09<24:20,  8.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ʊnt vas zɪnt diː ʃøːnstən“ ɛɐʔaɪ̯ɡnɪsə ɪm leːbən?\n",
      " [!] Character '“' not found in the vocabulary. Discarding it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 905/12161 [02:04<23:10,  8.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vaɪ̯naxtən — ʔatvɛntskalɛndɐ zɛlbɐ bastəln ɪst ʃøːn.\n",
      " [!] Character '—' not found in the vocabulary. Discarding it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 914/12161 [02:05<23:31,  7.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baɪ̯də ɡeːɡnɐ zɪnt nɔx ʔʊnɡəʃlaːɡən ʔɪn diːzəʁ bʊndɛsliːɡa zɛzõː.\n",
      " [!] Character 'õ' not found in the vocabulary. Discarding it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 937/12161 [02:08<21:30,  8.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ɡʁyːnəs lɪçt, nɪçt dʊŋkeːlɡʁyːn ʔoːdɐ oːʁãːʃ.\n",
      " [!] Character 'ã' not found in the vocabulary. Discarding it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 1894/12161 [03:57<21:27,  7.97it/s]\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[WinError 32] Der Prozess kann nicht auf die Datei zugreifen, da sie von einem anderen Prozess verwendet wird: 'J:/Text to Speech/notebooks/tts_train_dir/run-May-19-2023_04+08PM-c81bf18\\\\events.out.tfevents.1684505289.Kai-PC'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[1;32mJ:\\TTS\\TTS\\tts\\datasets\\dataset.py:617\u001B[0m, in \u001B[0;36mPhonemeDataset.compute_or_load\u001B[1;34m(self, file_name, text, language)\u001B[0m\n\u001B[0;32m    616\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 617\u001B[0m     ids \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcache_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    618\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m:\n",
      "File \u001B[1;32mJ:\\Text to Speech\\venv310\\lib\\site-packages\\numpy\\lib\\npyio.py:405\u001B[0m, in \u001B[0;36mload\u001B[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001B[0m\n\u001B[0;32m    404\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 405\u001B[0m     fid \u001B[38;5;241m=\u001B[39m stack\u001B[38;5;241m.\u001B[39menter_context(\u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mos_fspath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m)\n\u001B[0;32m    406\u001B[0m     own_fid \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'tts_train_dir\\\\phoneme_cache\\\\I3dhdnNcMzMzNzU4NjViMDFjZmMxOWQxZjk4M2ZjZDNkMjY4Yjc=_phoneme.npy'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[1;32mJ:\\Text to Speech\\venv310\\lib\\site-packages\\trainer\\trainer.py:1591\u001B[0m, in \u001B[0;36mTrainer.fit\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1590\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1591\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1592\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mrank \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[1;32mJ:\\Text to Speech\\venv310\\lib\\site-packages\\trainer\\trainer.py:1544\u001B[0m, in \u001B[0;36mTrainer._fit\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mskip_train_epoch \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstart_with_eval:\n\u001B[1;32m-> 1544\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1545\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mrun_eval:\n",
      "File \u001B[1;32mJ:\\Text to Speech\\venv310\\lib\\site-packages\\trainer\\trainer.py:1292\u001B[0m, in \u001B[0;36mTrainer.train_epoch\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1291\u001B[0m \u001B[38;5;66;03m# initialize the data loader\u001B[39;00m\n\u001B[1;32m-> 1292\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_loader \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_train_dataloader\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1293\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining_assets\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1294\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_samples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1295\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1296\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1297\u001B[0m \u001B[38;5;66;03m# set model to training mode\u001B[39;00m\n",
      "File \u001B[1;32mJ:\\Text to Speech\\venv310\\lib\\site-packages\\trainer\\trainer.py:803\u001B[0m, in \u001B[0;36mTrainer.get_train_dataloader\u001B[1;34m(self, training_assets, samples, verbose)\u001B[0m\n\u001B[0;32m    801\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m loader\n\u001B[1;32m--> 803\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_loader\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    804\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    805\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    806\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtraining_assets\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    807\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    808\u001B[0m \u001B[43m    \u001B[49m\u001B[43msamples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    809\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    810\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_gpus\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    811\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mJ:\\Text to Speech\\venv310\\lib\\site-packages\\trainer\\trainer.py:767\u001B[0m, in \u001B[0;36mTrainer._get_loader\u001B[1;34m(self, model, config, assets, is_eval, samples, verbose, num_gpus)\u001B[0m\n\u001B[0;32m    766\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(model, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mget_data_loader\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m--> 767\u001B[0m         loader \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_data_loader\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    768\u001B[0m \u001B[43m            \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43massets\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43massets\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_eval\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msamples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msamples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_gpus\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_gpus\u001B[49m\n\u001B[0;32m    769\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    770\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loader\n",
      "File \u001B[1;32mJ:\\TTS\\TTS\\tts\\models\\base_tts.py:315\u001B[0m, in \u001B[0;36mBaseTTS.get_data_loader\u001B[1;34m(self, config, assets, is_eval, samples, verbose, num_gpus, rank)\u001B[0m\n\u001B[0;32m    314\u001B[0m \u001B[38;5;66;03m# init dataloader\u001B[39;00m\n\u001B[1;32m--> 315\u001B[0m dataset \u001B[38;5;241m=\u001B[39m \u001B[43mTTSDataset\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    316\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutputs_per_step\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mr\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    317\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompute_linear_spec\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlower\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtacotron\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_linear_spec\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    318\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompute_f0\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompute_f0\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    319\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf0_cache_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mf0_cache_path\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    320\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompute_energy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompute_energy\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    321\u001B[0m \u001B[43m    \u001B[49m\u001B[43menergy_cache_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43menergy_cache_path\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    322\u001B[0m \u001B[43m    \u001B[49m\u001B[43msamples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msamples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    323\u001B[0m \u001B[43m    \u001B[49m\u001B[43map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43map\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    324\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_wav\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreturn_wav\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mreturn_wav\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    325\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_group_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mis_eval\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_group_size\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    326\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmin_text_len\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmin_text_len\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    327\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_text_len\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_text_len\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    328\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmin_audio_len\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmin_audio_len\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    329\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_audio_len\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_audio_len\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    330\u001B[0m \u001B[43m    \u001B[49m\u001B[43mphoneme_cache_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mphoneme_cache_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    331\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprecompute_num_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprecompute_num_workers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    332\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_noise_augment\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mis_eval\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43muse_noise_augment\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    333\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    334\u001B[0m \u001B[43m    \u001B[49m\u001B[43mspeaker_id_mapping\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mspeaker_id_mapping\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    335\u001B[0m \u001B[43m    \u001B[49m\u001B[43md_vector_mapping\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43md_vector_mapping\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43muse_d_vector_file\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    336\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtokenizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    337\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstart_by_longest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart_by_longest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    338\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlanguage_id_mapping\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlanguage_id_mapping\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    339\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    341\u001B[0m \u001B[38;5;66;03m# wait all the DDP process to be ready\u001B[39;00m\n",
      "File \u001B[1;32mJ:\\TTS\\TTS\\tts\\datasets\\dataset.py:159\u001B[0m, in \u001B[0;36mTTSDataset.__init__\u001B[1;34m(self, outputs_per_step, compute_linear_spec, ap, samples, tokenizer, compute_f0, compute_energy, f0_cache_path, energy_cache_path, return_wav, batch_group_size, min_text_len, max_text_len, min_audio_len, max_audio_len, phoneme_cache_path, precompute_num_workers, speaker_id_mapping, d_vector_mapping, language_id_mapping, use_noise_augment, start_by_longest, verbose)\u001B[0m\n\u001B[0;32m    158\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtokenizer\u001B[38;5;241m.\u001B[39muse_phonemes:\n\u001B[1;32m--> 159\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mphoneme_dataset \u001B[38;5;241m=\u001B[39m \u001B[43mPhonemeDataset\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    160\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msamples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtokenizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mphoneme_cache_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprecompute_num_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprecompute_num_workers\u001B[49m\n\u001B[0;32m    161\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    163\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m compute_f0:\n",
      "File \u001B[1;32mJ:\\TTS\\TTS\\tts\\datasets\\dataset.py:598\u001B[0m, in \u001B[0;36mPhonemeDataset.__init__\u001B[1;34m(self, samples, tokenizer, cache_path, precompute_num_workers)\u001B[0m\n\u001B[0;32m    597\u001B[0m os\u001B[38;5;241m.\u001B[39mmakedirs(cache_path)\n\u001B[1;32m--> 598\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprecompute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprecompute_num_workers\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mJ:\\TTS\\TTS\\tts\\datasets\\dataset.py:638\u001B[0m, in \u001B[0;36mPhonemeDataset.precompute\u001B[1;34m(self, num_workers)\u001B[0m\n\u001B[0;32m    635\u001B[0m dataloder \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mDataLoader(\n\u001B[0;32m    636\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39mbatch_size, dataset\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, num_workers\u001B[38;5;241m=\u001B[39mnum_workers, collate_fn\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcollate_fn\n\u001B[0;32m    637\u001B[0m )\n\u001B[1;32m--> 638\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m dataloder:\n\u001B[0;32m    639\u001B[0m     pbar\u001B[38;5;241m.\u001B[39mupdate(batch_size)\n",
      "File \u001B[1;32mJ:\\Text to Speech\\venv310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    632\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 633\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    634\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32mJ:\\Text to Speech\\venv310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    676\u001B[0m index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 677\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    678\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n",
      "File \u001B[1;32mJ:\\Text to Speech\\venv310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 51\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32mJ:\\Text to Speech\\venv310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 51\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32mJ:\\TTS\\TTS\\tts\\datasets\\dataset.py:602\u001B[0m, in \u001B[0;36mPhonemeDataset.__getitem__\u001B[1;34m(self, index)\u001B[0m\n\u001B[0;32m    601\u001B[0m item \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msamples[index]\n\u001B[1;32m--> 602\u001B[0m ids \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_or_load\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstring2filename\u001B[49m\u001B[43m(\u001B[49m\u001B[43mitem\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43maudio_unique_name\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mitem\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtext\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mitem\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlanguage\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    603\u001B[0m ph_hat \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtokenizer\u001B[38;5;241m.\u001B[39mids_to_text(ids)\n",
      "File \u001B[1;32mJ:\\TTS\\TTS\\tts\\datasets\\dataset.py:619\u001B[0m, in \u001B[0;36mPhonemeDataset.compute_or_load\u001B[1;34m(self, file_name, text, language)\u001B[0m\n\u001B[0;32m    618\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m:\n\u001B[1;32m--> 619\u001B[0m     ids \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtokenizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtext_to_ids\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlanguage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlanguage\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    620\u001B[0m     np\u001B[38;5;241m.\u001B[39msave(cache_path, ids)\n",
      "File \u001B[1;32mJ:\\TTS\\TTS\\tts\\utils\\text\\tokenizer.py:110\u001B[0m, in \u001B[0;36mTTSTokenizer.text_to_ids\u001B[1;34m(self, text, language)\u001B[0m\n\u001B[0;32m    109\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39muse_phonemes:\n\u001B[1;32m--> 110\u001B[0m     text \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mphonemizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mphonemize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mseparator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlanguage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlanguage\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    111\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39madd_blank:\n",
      "File \u001B[1;32mJ:\\TTS\\TTS\\tts\\utils\\text\\phonemizers\\base.py:132\u001B[0m, in \u001B[0;36mBasePhonemizer.phonemize\u001B[1;34m(self, text, separator, language)\u001B[0m\n\u001B[0;32m    131\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m text:\n\u001B[1;32m--> 132\u001B[0m     p \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_phonemize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mseparator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    133\u001B[0m     phonemized\u001B[38;5;241m.\u001B[39mappend(p)\n",
      "File \u001B[1;32mJ:\\TTS\\TTS\\tts\\utils\\text\\phonemizers\\gruut_wrapper.py:110\u001B[0m, in \u001B[0;36mGruut._phonemize\u001B[1;34m(self, text, separator)\u001B[0m\n\u001B[0;32m    109\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_phonemize\u001B[39m(\u001B[38;5;28mself\u001B[39m, text, separator):\n\u001B[1;32m--> 110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mphonemize_gruut\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mseparator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtie\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mJ:\\TTS\\TTS\\tts\\utils\\text\\phonemizers\\gruut_wrapper.py:77\u001B[0m, in \u001B[0;36mGruut.phonemize_gruut\u001B[1;34m(self, text, separator, tie)\u001B[0m\n\u001B[0;32m     76\u001B[0m ph_list \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m---> 77\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m sentence \u001B[38;5;129;01min\u001B[39;00m gruut\u001B[38;5;241m.\u001B[39msentences(text, lang\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlanguage, espeak\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39muse_espeak_phonemes):\n\u001B[0;32m     78\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m word \u001B[38;5;129;01min\u001B[39;00m sentence:\n",
      "File \u001B[1;32mJ:\\Text to Speech\\venv310\\lib\\site-packages\\gruut\\__init__.py:79\u001B[0m, in \u001B[0;36msentences\u001B[1;34m(text, lang, ssml, espeak, major_breaks, minor_breaks, punctuations, explicit_lang, phonemes, break_phonemes, pos, **process_args)\u001B[0m\n\u001B[0;32m     78\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m text_processor \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m---> 79\u001B[0m graph, root \u001B[38;5;241m=\u001B[39m text_processor(text, lang\u001B[38;5;241m=\u001B[39mlang, ssml\u001B[38;5;241m=\u001B[39mssml, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mprocess_args)\n\u001B[0;32m     81\u001B[0m \u001B[38;5;28;01myield from\u001B[39;00m text_processor\u001B[38;5;241m.\u001B[39msentences(\n\u001B[0;32m     82\u001B[0m     graph,\n\u001B[0;32m     83\u001B[0m     root,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     90\u001B[0m     pos\u001B[38;5;241m=\u001B[39mpos,\n\u001B[0;32m     91\u001B[0m )\n",
      "File \u001B[1;32mJ:\\Text to Speech\\venv310\\lib\\site-packages\\gruut\\text_processor.py:440\u001B[0m, in \u001B[0;36mTextProcessor.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    439\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Processes text or SSML\"\"\"\u001B[39;00m\n\u001B[1;32m--> 440\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mJ:\\Text to Speech\\venv310\\lib\\site-packages\\gruut\\text_processor.py:689\u001B[0m, in \u001B[0;36mTextProcessor.process\u001B[1;34m(self, text, lang, ssml, pos, phonemize, post_process, add_speak_tag, detect_numbers, detect_currency, detect_dates, detect_times, verbalize_numbers, verbalize_currency, verbalize_dates, verbalize_times, max_passes)\u001B[0m\n\u001B[0;32m    687\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    688\u001B[0m         \u001B[38;5;66;03m# Split by whitespace\u001B[39;00m\n\u001B[1;32m--> 689\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_pipeline_tokenize\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    690\u001B[0m \u001B[43m            \u001B[49m\u001B[43mgraph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    691\u001B[0m \u001B[43m            \u001B[49m\u001B[43mlast_sentence\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    692\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtext\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    693\u001B[0m \u001B[43m            \u001B[49m\u001B[43mword_phonemes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mword_phonemes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    694\u001B[0m \u001B[43m            \u001B[49m\u001B[43mscope_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mscope_kwargs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mWordNode\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    695\u001B[0m \u001B[43m            \u001B[49m\u001B[43min_inline_lexicon\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43min_inline_lexicon\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    696\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    698\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem_or_text, EndElement):\n\u001B[0;32m    699\u001B[0m     \u001B[38;5;66;03m# End of an element (e.g., </s>)\u001B[39;00m\n",
      "File \u001B[1;32mJ:\\Text to Speech\\venv310\\lib\\site-packages\\gruut\\text_processor.py:1612\u001B[0m, in \u001B[0;36mTextProcessor._pipeline_tokenize\u001B[1;34m(self, graph, parent_node, text, word_phonemes, scope_kwargs, in_inline_lexicon)\u001B[0m\n\u001B[0;32m   1610\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m in_lexicon:\n\u001B[0;32m   1611\u001B[0m     \u001B[38;5;66;03m# Check main language lexicon\u001B[39;00m\n\u001B[1;32m-> 1612\u001B[0m     in_lexicon \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_is_word_in_lexicon\u001B[49m\u001B[43m(\u001B[49m\u001B[43mword_text_norm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msettings\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1614\u001B[0m word_node \u001B[38;5;241m=\u001B[39m WordNode(\n\u001B[0;32m   1615\u001B[0m     node\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(graph),\n\u001B[0;32m   1616\u001B[0m     text\u001B[38;5;241m=\u001B[39mword_text_norm,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1620\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mword_kwargs,\n\u001B[0;32m   1621\u001B[0m )\n",
      "File \u001B[1;32mJ:\\Text to Speech\\venv310\\lib\\site-packages\\gruut\\text_processor.py:2037\u001B[0m, in \u001B[0;36mTextProcessor._is_word_in_lexicon\u001B[1;34m(self, word, settings)\u001B[0m\n\u001B[0;32m   2035\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 2037\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mbool\u001B[39m(\u001B[43msettings\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlookup_phonemes\u001B[49m\u001B[43m(\u001B[49m\u001B[43mword\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdo_transforms\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m)\n",
      "File \u001B[1;32mJ:\\Text to Speech\\venv310\\lib\\site-packages\\gruut\\lang.py:882\u001B[0m, in \u001B[0;36mDelayedSqlitePhonemizer.__call__\u001B[1;34m(self, word, role, do_transforms)\u001B[0m\n\u001B[0;32m    881\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mphonemizer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 882\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mphonemizer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mword\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrole\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrole\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdo_transforms\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdo_transforms\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mJ:\\Text to Speech\\venv310\\lib\\site-packages\\gruut\\phonemize.py:91\u001B[0m, in \u001B[0;36mSqlitePhonemizer.__call__\u001B[1;34m(self, word, role, do_transforms)\u001B[0m\n\u001B[0;32m     90\u001B[0m \u001B[38;5;66;03m# Load pronunciations for word from database.\u001B[39;00m\n\u001B[1;32m---> 91\u001B[0m cursor \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdb_conn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     92\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mSELECT role, phonemes FROM word_phonemes WHERE word = ? ORDER BY pron_order\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     93\u001B[0m \u001B[43m    \u001B[49m\u001B[43m(\u001B[49m\u001B[43mlookup_word\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     94\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     96\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m row \u001B[38;5;129;01min\u001B[39;00m cursor:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mPermissionError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[28], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mJ:\\Text to Speech\\venv310\\lib\\site-packages\\trainer\\trainer.py:1597\u001B[0m, in \u001B[0;36mTrainer.fit\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1595\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallbacks\u001B[38;5;241m.\u001B[39mon_keyboard_interrupt(\u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m   1596\u001B[0m \u001B[38;5;66;03m# if the output folder is empty remove the run.\u001B[39;00m\n\u001B[1;32m-> 1597\u001B[0m \u001B[43mremove_experiment_folder\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moutput_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1598\u001B[0m \u001B[38;5;66;03m# clear the DDP processes\u001B[39;00m\n\u001B[0;32m   1599\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_gpus \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n",
      "File \u001B[1;32mJ:\\Text to Speech\\venv310\\lib\\site-packages\\trainer\\generic_utils.py:64\u001B[0m, in \u001B[0;36mremove_experiment_folder\u001B[1;34m(experiment_path)\u001B[0m\n\u001B[0;32m     62\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m checkpoint_files:\n\u001B[0;32m     63\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m fs\u001B[38;5;241m.\u001B[39mexists(experiment_path):\n\u001B[1;32m---> 64\u001B[0m         \u001B[43mfs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexperiment_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrecursive\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m     65\u001B[0m         logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m ! Run is removed from \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, experiment_path)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32mJ:\\Text to Speech\\venv310\\lib\\site-packages\\fsspec\\implementations\\local.py:171\u001B[0m, in \u001B[0;36mLocalFileSystem.rm\u001B[1;34m(self, path, recursive, maxdepth)\u001B[0m\n\u001B[0;32m    169\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m osp\u001B[38;5;241m.\u001B[39mabspath(p) \u001B[38;5;241m==\u001B[39m os\u001B[38;5;241m.\u001B[39mgetcwd():\n\u001B[0;32m    170\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot delete current working directory\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 171\u001B[0m     \u001B[43mshutil\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrmtree\u001B[49m\u001B[43m(\u001B[49m\u001B[43mp\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    172\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    173\u001B[0m     os\u001B[38;5;241m.\u001B[39mremove(p)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\shutil.py:750\u001B[0m, in \u001B[0;36mrmtree\u001B[1;34m(path, ignore_errors, onerror)\u001B[0m\n\u001B[0;32m    748\u001B[0m     \u001B[38;5;66;03m# can't continue even if onerror hook returns\u001B[39;00m\n\u001B[0;32m    749\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m--> 750\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_rmtree_unsafe\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43monerror\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\shutil.py:620\u001B[0m, in \u001B[0;36m_rmtree_unsafe\u001B[1;34m(path, onerror)\u001B[0m\n\u001B[0;32m    618\u001B[0m             os\u001B[38;5;241m.\u001B[39munlink(fullname)\n\u001B[0;32m    619\u001B[0m         \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m:\n\u001B[1;32m--> 620\u001B[0m             \u001B[43monerror\u001B[49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munlink\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfullname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msys\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexc_info\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    621\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    622\u001B[0m     os\u001B[38;5;241m.\u001B[39mrmdir(path)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\shutil.py:618\u001B[0m, in \u001B[0;36m_rmtree_unsafe\u001B[1;34m(path, onerror)\u001B[0m\n\u001B[0;32m    616\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    617\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 618\u001B[0m         \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munlink\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfullname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    619\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m:\n\u001B[0;32m    620\u001B[0m         onerror(os\u001B[38;5;241m.\u001B[39munlink, fullname, sys\u001B[38;5;241m.\u001B[39mexc_info())\n",
      "\u001B[1;31mPermissionError\u001B[0m: [WinError 32] Der Prozess kann nicht auf die Datei zugreifen, da sie von einem anderen Prozess verwendet wird: 'J:/Text to Speech/notebooks/tts_train_dir/run-May-19-2023_04+08PM-c81bf18\\\\events.out.tfevents.1684505289.Kai-PC'"
     ]
    }
   ],
   "source": [
    "trainer.fit()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T14:12:11.496374500Z",
     "start_time": "2023-05-19T14:08:12.670149600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install tensorboard\n",
    "!tensorboard --logdir=tts_train_dir"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import glob, os\n",
    "output_path = \"tts_train_dir\"\n",
    "ckpts = sorted([f for f in glob.glob(output_path+\"/*/*.pth\")])\n",
    "configs = sorted([f for f in glob.glob(output_path+\"/*/*.json\")])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    " !tts --text \"Text for TTS\" \\\n",
    "    --model_path $test_ckpt \\\n",
    "    --config_path $test_config \\\n",
    "    --out_path out.wav"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import IPython\n",
    "IPython.display.Audio(\"out.wav\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
