# -*- coding: utf-8 -*-
"""Hifigan - Vocoder Train.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1h6lhUv2J3EIVpNFMeDi0ieM8xZUbVHWI
"""

#!gdown https://zenodo.org/record/7265581/files/ThorstenVoice-Dataset_2022.10.zip
#!unzip /content/ThorstenVoice-Dataset_2022.10.zip
#!rm /content/ThorstenVoice-Dataset_2022.10.zip
#!rm -r /content/__MACOSX

#!pip install TTS

import os
from trainer import Trainer, TrainerArgs
from TTS.utils.audio import AudioProcessor
from TTS.utils.downloaders import download_thorsten_de
from TTS.vocoder.configs import HifiganConfig
from TTS.vocoder.datasets.preprocess import load_wav_data
from TTS.vocoder.models.gan import GAN
import torch.multiprocessing as mp
import torch

if __name__ == '__main__':
    print(torch.cuda.is_available())
    print(torch.cuda.device_count())

    # GPU Sichtbar machen, sofern GPU vorhanden
    if torch.cuda.is_available():
        if torch.cuda.device_count() > 0: # Haupt GPU verwenden!
            os.environ["CUDA_VISIBLE_DEVICES"] = "0"

    #Ausgabeverzeichnis definieren
    output_path = "/content/train"

    if not os.path.exists(output_path):
        os.makedirs(output_path)

    # HifiganConfig aus TTS Library parameter füllen
    # Bei Testläufen waren max. 3 CPUs aktiv, daher nur 4 Cores verwendet
    # Mehr bindet unnötig Arbeitsspeicher
    cpu_cores = 4

    if mp.cpu_count() < cpu_cores:
        cpu_cores = mp.cpu_count()

    # Konfiguration des Vocoders, aus Tutorial for beginners übernommen
    # epochen auf 150 angepasst
    config = HifiganConfig(
        batch_size=32,
        eval_batch_size=16,
        num_loader_workers=cpu_cores,
        num_eval_loader_workers=cpu_cores,
        run_eval=True,
        test_delay_epochs=5,
        epochs=150,
        seq_len=8192,
        pad_short=2000,
        use_noise_augment=True,
        eval_split_size=10,
        print_step=25,
        print_eval=False,
        mixed_precision=False,
        lr_gen=1e-4,
        lr_disc=1e-4,
        data_path="/content/ThorstenVoice-Dataset_2022.10/",
        output_path=output_path,
        save_step=1000,
        save_best_after=2500
    )

    # Audio-Verarbeitung initialisieren
    ap = AudioProcessor(**config.audio.to_dict())
    ap.sample_rate = 22050

    # Trainingsdaten laden, Aufteilung Training-/Testdaten übernimmt TTS library
    eval_samples, train_samples = load_wav_data(config.data_path, config.eval_split_size)

    # Modell intialisieren mit Config und AudioProcessor
    model = GAN(config, ap)

    # Trainer wird ebenfalls geliefert, Parameter werden hier zusammengeführt:
    # - Config
    # - Ausgabeordner
    # - Modell
    # - Training und Testdatensätze
    trainer = Trainer(
        TrainerArgs(), config, output_path, model=model, train_samples=train_samples, eval_samples=eval_samples
    )

    # Training starten
    trainer.fit()